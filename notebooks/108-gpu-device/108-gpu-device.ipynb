{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85bb873e-562a-4d60-9536-b6b88aecb5c2",
   "metadata": {},
   "source": [
    "# Working with GPUs in OpenVINO™\n",
    "\n",
    "This tutorial provides a high-level overview of working with GPUs in OpenVINO. It shows users how to use Query Device to list system GPUs and check their properties, and it explains some of the key properties. It shows how to compile a model on GPU with performance hints and how to use multiple GPUs using MULTI or CUMULATIVE_THROUGHPUT. \n",
    "\n",
    "The tutorial shows example commands for benchmark_app that users can run to compare GPU performance in different configurations. It also provides code for a basic end-to-end application that compiles a model on GPU and uses it to run inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7253ed-d8a1-4475-8e83-263336639157",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f9f13-63a4-4b2d-95e3-9a82c1e9cebd",
   "metadata": {},
   "source": [
    "1. Background and context on how GPUs are used to speed up inference\n",
    "2. Introduce OpenVINO’s ability to run inference with GPUs\n",
    "3. How to configure OpenVINO to work with GPUs (link to Configuration for GPU with OpenVINO page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f35f17-5209-43d6-b3b5-db35efb1f42e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Checking GPUs with Query Device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3ce23-2b04-4014-9eeb-c2b8309eb103",
   "metadata": {},
   "source": [
    "1. List GPUs with ie.get_available_devices\n",
    "2. Check properties with ie.get_property\n",
    "3. Brief descriptions of key properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e91abc-6118-4532-9817-6ef44c51b0c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### List GPUs with core.get_available_devices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76b6152-3915-415a-987b-c30935462007",
   "metadata": {},
   "source": [
    "Firstly, in order to use GPUs, we must make sure our system is detecting them correctly.\n",
    "Running the following cell should output a list of compatible OpenVINO devices, in which our Intel GPUs should appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8260bef-63c4-45f3-9ffd-4cc3ac892680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPU']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openvino.runtime import Core\n",
    "\n",
    "core = Core()\n",
    "core.available_devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e266c79-7bb9-4907-9204-87b688087cbf",
   "metadata": {},
   "source": [
    "If the GPUs are installed correctly in the system and still don't appear in the list, we should follow the steps described [here](https://docs.openvino.ai/latest/openvino_docs_install_guides_configurations_for_intel_gpu.html) and try again. Once we have the GPUs working with OpenVINO we can proceed with the next sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0491c07-0b6d-483f-a4d6-d3f7b5ec0c81",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check properties with core.get_property"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54399a50-31cf-48bd-bf98-6dea0c0b1b20",
   "metadata": {},
   "source": [
    "Now, to get information and customize the behavior of our GPUs, we can use device properties. Devices in OpenVINO, such as CPUs and GPUs, have two types of properties: read-only and read-write. The former mainly shows information about the hardware itself like the device name or supported data types, while the latter allows us to tweak how the model is compiled, for instance to reduce latency or increase throughput."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7509b6-67e3-46fb-bb23-5f46c58b0fc1",
   "metadata": {},
   "source": [
    "So, to get the value of a property, such as the device name, we can use the `core.get_property` method as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eacdd5be-5d75-41d5-a51b-a376cb063b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"CPU\"\n",
    "core.get_property(device, \"FULL_DEVICE_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac3129a-129f-49aa-aba0-71ae1e892ada",
   "metadata": {},
   "source": [
    "The devices also have a specific property, called `SUPPORTED_PROPERTIES`, that allows us to see all the available properties in the device (including the `SUPPORTED_PROPERTIES` itself). To do this, we repeat the above command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdea1793-0784-40a1-a279-ca73a6994ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SUPPORTED_PROPERTIES': 'RO',\n",
       " 'AVAILABLE_DEVICES': 'RO',\n",
       " 'RANGE_FOR_ASYNC_INFER_REQUESTS': 'RO',\n",
       " 'RANGE_FOR_STREAMS': 'RO',\n",
       " 'FULL_DEVICE_NAME': 'RO',\n",
       " 'OPTIMIZATION_CAPABILITIES': 'RO',\n",
       " 'CACHING_PROPERTIES': 'RO',\n",
       " 'CACHE_DIR': 'RO',\n",
       " 'NUM_STREAMS': 'RW',\n",
       " 'AFFINITY': 'RW',\n",
       " 'INFERENCE_NUM_THREADS': 'RW',\n",
       " 'PERF_COUNT': 'RW',\n",
       " 'INFERENCE_PRECISION_HINT': 'RW',\n",
       " 'PERFORMANCE_HINT': 'RW',\n",
       " 'PERFORMANCE_HINT_NUM_REQUESTS': 'RW'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core.get_property(device, \"SUPPORTED_PROPERTIES\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c2d865-4223-4b50-804d-b4659e4984e2",
   "metadata": {},
   "source": [
    "Note that the value for each property has either a \"RO\" or \"RW\", which corresponds to the two types mentioned previously, \"**R**ead-**O**nly\" and \"**R**-**W**rite\" respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88546b71-2ae8-4519-b9b7-a54f444e204f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Brief descriptions of key properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c181d13-b5de-4878-869b-86bf8662f497",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### PERFORMANCE_HINT\n",
    "#### INFERENCE_PRECISION_HINT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5a6b5d-623b-4893-8a6d-051ac670f288",
   "metadata": {},
   "source": [
    "#### Current values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a913dc-8125-4270-9b3d-8e38c8324912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             AVAILABLE_DEVICES: ['']\n",
      "RANGE_FOR_ASYNC_INFER_REQUESTS: (1, 1, 1)\n",
      "             RANGE_FOR_STREAMS: (1, 12)\n",
      "              FULL_DEVICE_NAME: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz\n",
      "     OPTIMIZATION_CAPABILITIES: ['FP32', 'FP16', 'INT8', 'BIN', 'EXPORT_IMPORT']\n",
      "            CACHING_PROPERTIES: {}\n",
      "                     CACHE_DIR: \n",
      "                   NUM_STREAMS: 1\n",
      "                      AFFINITY: Affinity.NONE\n",
      "         INFERENCE_NUM_THREADS: 0\n",
      "                    PERF_COUNT: False\n",
      "      INFERENCE_PRECISION_HINT: <Type: 'float32'>\n",
      "              PERFORMANCE_HINT: PerformanceMode.UNDEFINED\n",
      " PERFORMANCE_HINT_NUM_REQUESTS: 0\n"
     ]
    }
   ],
   "source": [
    "for prop in core.get_property(device, \"SUPPORTED_PROPERTIES\"):\n",
    "    if prop != \"SUPPORTED_PROPERTIES\":\n",
    "        print(f\"{prop:>30}: {core.get_property(device, prop)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131bd0f9-9b1e-4fc1-ad09-3960e1d6c50f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compiling a Model on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e33c10-f8cc-494d-bfa7-567787590946",
   "metadata": {},
   "source": [
    "1. Compile with default configuration (ie.compile_model(model, “GPU”)\n",
    "2. Throughput and latency performance hints\n",
    "3. Using multiple GPUs with multi-device and cumulative throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc043aa-8729-45bc-9e98-6b3daea9f271",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compile with default configuration (ie.compile_model(model, “GPU”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57f7d00e-ebe5-456d-8643-112e9d8c860d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Device with \"GPU\" name is not registered in the OpenVINO Runtime",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-956e6be73142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../001-hello-world/model/v3-small_224_1.0_float.xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcompiled_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"GPU\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/bdti/openvino_env/lib/python3.10/site-packages/openvino/runtime/ie_api.py\u001b[0m in \u001b[0;36mcompile_model\u001b[0;34m(self, model, device_name, config)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         return CompiledModel(\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m         )\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Device with \"GPU\" name is not registered in the OpenVINO Runtime"
     ]
    }
   ],
   "source": [
    "model = core.read_model(model=\"../001-hello-world/model/v3-small_224_1.0_float.xml\")\n",
    "compiled_model = core.compile_model(model, \"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5054f912-63cc-4a59-951e-674723287e32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compiled_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-98de713be352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mprop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompiled_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_property\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SUPPORTED_PROPERTIES\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprop\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"SUPPORTED_PROPERTIES\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{prop:>30}: {compiled_model.get_property(prop)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compiled_model' is not defined"
     ]
    }
   ],
   "source": [
    "for prop in compiled_model.get_property(\"SUPPORTED_PROPERTIES\"):\n",
    "    if prop != \"SUPPORTED_PROPERTIES\":\n",
    "        print(f\"{prop:>30}: {compiled_model.get_property(prop)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa916d7-4626-4f54-9b34-954eca19aafb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Throughput and latency performance hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507684aa-3a40-46a2-a7bf-65a10b56ce9f",
   "metadata": {},
   "source": [
    "##### Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1114f4ec-32a6-4b46-804d-b81eea8a6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = core.compile_model(model, \"CPU\", {\"PERFORMANCE_HINT\": \"THROUGHPUT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9638b8d-daeb-422b-bb79-92248e11f208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PerformanceMode.THROUGHPUT: 2>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.get_property(\"PERFORMANCE_HINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6d0dab-11bf-489f-825c-f142327bd9ad",
   "metadata": {},
   "source": [
    "##### Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8983f01-d894-4519-93c4-d9f8b5187362",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_model = core.compile_model(model, \"CPU\", {\"PERFORMANCE_HINT\": \"LATENCY\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20904c05-3c07-48d3-a8b0-2d273b80cf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PerformanceMode.LATENCY: 1>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled_model.get_property(\"PERFORMANCE_HINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a98815-669e-4868-a5f3-7104d6887fb3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Using multiple GPUs with multi-device and cumulative throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99351910-c54c-4f55-b1ce-eb74125a9dbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Performance Comparison with benchmark_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f453eca-41ac-42fc-b77b-9aa8d8e3ab20",
   "metadata": {},
   "source": [
    "1. Commands showing users how to run benchmark_app on GPU with various performance hints\n",
    "2. Show performance results with a basic model (person-detection-0303, perhaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d079dae9-c08d-4343-913e-7569a83718c8",
   "metadata": {},
   "source": [
    "For further details check https://docs.openvino.ai/latest/openvino_inference_engine_tools_benchmark_tool_README.html#benchmark-python-tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df239f8c-2597-46d4-86a0-c23bd1591a33",
   "metadata": {},
   "source": [
    "### Commands showing users how to run benchmark_app on GPU with various performance hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74c76637-f86c-41d5-8846-6e3946126084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Step 1/11] Parsing and validating input arguments\n",
      "[ INFO ] Parsing input parameters\n",
      "[Step 2/11] Loading OpenVINO Runtime\n",
      "[ INFO ] OpenVINO:\n",
      "[ INFO ] Build ................................. 2022.3.0-9052-9752fafe8eb-releases/2022/3\n",
      "[ INFO ] \n",
      "[ INFO ] Device info:\n",
      "[ ERROR ] Device with \"GPU\" name is not registered in the OpenVINO Runtime\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/juliomorero/Documents/bdti/openvino_env/lib/python3.10/site-packages/openvino/tools/benchmark/main.py\", line 104, in main\n",
      "    benchmark.print_version_info()\n",
      "  File \"/Users/juliomorero/Documents/bdti/openvino_env/lib/python3.10/site-packages/openvino/tools/benchmark/benchmark.py\", line 48, in print_version_info\n",
      "    for device, version in self.core.get_versions(self.device).items():\n",
      "RuntimeError: Device with \"GPU\" name is not registered in the OpenVINO Runtime\n"
     ]
    }
   ],
   "source": [
    "!benchmark_app -m notebooks/001-hello-world/model/v3-small_224_1.0_float.xml -hint latency -d GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ecf50d-179d-415e-be3a-c57f53149b67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!benchmark_app -m notebooks/001-hello-world/model/v3-small_224_1.0_float.xml -hint latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eab12ce-3e31-4efc-855d-37c44073af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!benchmark_app -m notebooks/001-hello-world/model/v3-small_224_1.0_float.xml -hint throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d618c8-6a8b-482d-adf6-d78795c30107",
   "metadata": {},
   "outputs": [],
   "source": [
    "!benchmark_app -m notebooks/001-hello-world/model/v3-small_224_1.0_float.xml -hint cumulative_throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81464f73-ef33-47fa-9239-7a817a1ce35b",
   "metadata": {},
   "source": [
    "### Show performance results with a basic model (person-detection-0303, perhaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fd1496-996d-49d8-80b9-3bfb3dda9729",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Basic Application Using GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bacb918-3668-4e72-92ba-a15db658c369",
   "metadata": {},
   "source": [
    "1. Provide end-to-end sample code for running inference on GPU in a basic application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fb6bb6-0d1c-4b0b-8a0b-efb5667816ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb4f28-2917-45ca-8fa0-8c670c0348bc",
   "metadata": {},
   "source": [
    "1. GPUs are easy to use with OpenVINO and considerably boost performance\n",
    "2. Links to OpenVINO documentation where readers can learn more"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
